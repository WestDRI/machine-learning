#+title: AI, machine learning, deep learning
#+description: Zoom
#+colordes: #e86e0a
#+slug: 02_ml
#+weight: 2

* Zoom session 1, part 2

#+BEGIN_def
/Topic:/ {{<m>}} Introduction to general concepts of machine learning.
#+END_def

* Slides

/Click below to open the presentation.\\
Once in the presentation, navigate the slides with the left and right arrows and refresh any page to show the link that will take you back here./

#+BEGIN_export html
<a href="https://westgrid-slides.netlify.app/fastai_1/#/"><p align="center"><img src="/img/fastai_1_slides.png" title="" width="100%"/></p></a>
#+END_export

* Some notes from the slides

** Artificial intelligence and machine learning

Artificial intelligence is a vast field: any system mimicking animal intelligence falls in its scope.

Machine learning (ML) is a subfield of artificial intelligence that can be defined as computer programs whose performance at a task improves with experience.

Since this experience comes in the form of *data*, ML consists of feeding vast amounts of data to algorithms to strengthen *pathways*.

{{<br>}}
{{<img src="https://imgs.xkcd.com/comics/machine_learning.png" title="" width="%" line-height="1rem">}}
From <a href="https://xkcd.com/">xkcd.com</a>
{{</img>}}

*** Example in image recognition

Coding all the possible ways—pixel by pixel—that a picture can represent a certain object is an impossibly large task. By feeding examples of images of that object to a neural network however, we can train it to recognize that object in images that it has never seen (without explicitly programming how it does this!).

{{<br>}}
{{<img src="https://imgs.xkcd.com/comics/machine_learning_captcha.png" title="" width="%" line-height="1rem">}}
From <a href="https://xkcd.com/">xkcd.com</a>
{{</img>}}

** Neural networks

*** Neurons

Artificial neural networks (ANN) are one of the machine learning models (other models include decision trees or Bayesian networks). Their potential and popularity has truly exploded in recent years and this is what we will focus on in this course. In [[https://westgrid-ml.netlify.app/summerschool2020/pt-03-nn.html][the next lesson]], you will watch an excellent video by [[https://www.3blue1brown.com/][3Blue1Brown]] that will walk you through the concepts of neural networks. But in short, artificial neural networks are a series of layered units mimicking the concept of biological neurons: inputs are received by every unit of a layer, computed, then transmitted to units of the next layer. In the process of learning, experience strengthens some connections between units and weakens others.

In biological networks, the information consists of action potentials (neuron membrane rapid depolarizations) propagating through the network. In artificial ones, the information consists of tensors (multidimensional arrays) of weights and biases: each unit passes a weighted sum of an input tensor with an additional—possibly weighted—bias through an activation function before passing on the output tensor to the next layer of units.\\
/Note:/ {{<s>}}the bias allows to shift the output of the activation function to the right or to the left (i.e. it creates an offset).

/Schematic of a biological neuron:/
{{<br>}}
{{<img src="https://upload.wikimedia.org/wikipedia/commons/b/b5/Neuron.svg" title="" width="100%" line-height="2.5rem">}}
From <a href="https://commons.wikimedia.org/w/index.php?curid=1474927">Dhp1080, Wikipedia</a>
{{</img>}}

/Schematic of an artificial neuron:/
{{<br>}}
{{<img src="/img/artificial_neuron_nw.png" title="" width="70%" line-height="0rem">}}
<center>{{<m>}}{{<m>}}{{<m>}}{{<m>}}{{<m>}}{{<m>}}{{<m>}}{{<m>}}{{<m>}}{{<m>}}{{<m>}}{{<m>}}{{<m>}}{{<m>}}{{<m>}}{{<m>}}{{<m>}}{{<m>}}{{<m>}}{{<m>}}Modified from <a href="https://royalsocietypublishing.org/doi/10.1098/rsta.2019.0163">O.C. Akgun & J. Mei 2019</a></center>
{{</img>}}

*** Activation

The information in biological neurons is an all-or-nothing electrochemical pulse or action potential. Greater stimuli don’t produce stronger signals but increase firing frequency. In contrast, artificial neurons pass the computation of their inputs through an activation function and the output can take any of the values possible with that function.

/Threshold potential in biological neurons:/
{{<img src="/img/all_none_law_nw.png" title="" width="60%" line-height="0rem">}}
<center>{{<m>}}{{<m>}}{{<m>}}{{<m>}}{{<m>}}{{<m>}}{{<m>}}{{<m>}}{{<m>}}{{<m>}}{{<m>}}{{<m>}}{{<m>}}{{<m>}}{{<m>}}{{<m>}}Modified from <a href="https://commons.wikimedia.org/w/index.php?curid=78013076">Blacktc, Wikimedia</a></center>
{{</img>}}

{{<br>}}
/Some of the most common activation functions in artificial neurons:/

{{<img src="/img/act_func_nw.png" title="" width="60%" line-height="2.0rem">}}
<center>{{<m>}}{{<m>}}{{<m>}}{{<m>}}{{<m>}}{{<m>}}{{<m>}}{{<m>}}{{<m>}}{{<m>}}{{<m>}}{{<m>}}{{<m>}}{{<m>}}{{<m>}}{{<m>}}{{<m>}}{{<m>}}{{<m>}}From <a href="https://arxiv.org/abs/1908.08681">Diganta Misra 2019</a></center>
{{</img>}}

Which activation function to use depends on the type of problem and the available computing budget. Some early functions have fallen out of use while new ones have emerged (e.g. sigmoid got replaced by ReLU which is easier to train).

*** Networks

While biological neurons are connected in extremely intricate patterns, artificial ones follow a layered structure. Another difference in complexity is in the number of units: the human brain has 65–90 billion neurons. ANN have much fewer units.

/Neurons in mouse cortex:/
{{<img src="/img/brain_neurons.jpg" title="" width="70%" line-height="2.5rem">}}
<center>{{<m>}}{{<m>}}{{<m>}}{{<m>}}{{<m>}}{{<m>}}{{<m>}}{{<m>}}{{<m>}}{{<n>}}Neurons are in green, the dark branches are blood vessels. <br>
{{<m>}}{{<m>}}{{<m>}}{{<m>}}{{<m>}}{{<m>}}{{<m>}}{{<m>}}{{<m>}}{{<m>}}{{<m>}}{{<m>}}{{<m>}}{{<m>}}{{<m>}}{{<m>}}{{<m>}}{{<m>}}{{<m>}}{{<m>}}{{<m>}}Image by <a href="https://news.berkeley.edu/2020/03/19/high-speed-microscope-captures-fleeting-brain-signals/">Na Ji, UC Berkeley</a></center>
{{</img>}}

/Neural network with 2 hidden layers:/
{{<br>}}
{{<img src="/img/nn_multi_layer_nw.png" title="" width="80%" line-height="1.5rem">}}
<center>{{<m>}}{{<m>}}{{<m>}}{{<m>}}{{<m>}}{{<m>}}{{<m>}}{{<m>}}{{<m>}}{{<m>}}{{<m>}}{{<m>}}{{<m>}}{{<m>}}{{<m>}}{{<m>}}{{<m>}}{{<m>}}{{<m>}}{{<m>}}{{<m>}}{{<m>}}From <a href="https://themaverickmeerkat.com/2020-01-10-TicTacToe/">The Maverick Meerkat</a></center>
{{</img>}}

*** Learning

The process of learning in biological NN happens through neuron death or growth and through the creation or loss of synaptic connections between neurons. In ANN, learning happens through optimization algorithms such as gradient descent which minimize cross entropy loss functions by adjusting the weights and biases connecting each layer of neurons over many iterations (cross entropy is the difference between the predicted and the real distributions).

{{<br>}}
{{<img src="https://imgs.xkcd.com/comics/ai_hiring_algorithm.png" title="" width="%" line-height="1rem">}}
From <a href="https://xkcd.com/">xkcd.com</a>
{{</img>}}

We talk about /deep learning/ whenever a neural network has two or more hidden layers.

* Comments & questions
